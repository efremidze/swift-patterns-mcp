---
phase: 02-test-infrastructure
plan: 01
type: execute
---

<objective>
Add test coverage for core utility functions.

Purpose: Establish test patterns and cover the pure utility functions that other modules depend on.
Output: Test files for swift-analysis.ts and errors.ts with passing tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-phase.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

**Prior phase context:**
@.planning/phases/01-foundation-error-handling/01-01-SUMMARY.md

**Codebase context:**
@.planning/codebase/TESTING.md
@.planning/codebase/CONVENTIONS.md

**Files to test:**
@src/utils/swift-analysis.ts
@src/utils/errors.ts

**Existing test patterns (reference):**
@src/sources/free/sundell.test.ts

**Established patterns:**
- Vitest with `describe`, `it`, `expect`, `vi`
- Co-located test files (`*.test.ts` next to source)
- Mock external dependencies, test pure functions directly
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add tests for swift-analysis.ts</name>
  <files>src/utils/swift-analysis.test.ts</files>
  <action>
Create tests for the three pure functions:

1. `detectTopics(text, keywords)`:
   - Returns matching topics when keywords found
   - Returns empty array when no matches
   - Case-insensitive matching

2. `hasCodeContent(content)`:
   - Returns true for Swift keywords (func, class, struct, etc.)
   - Returns true for markdown code blocks
   - Returns true for HTML code tags
   - Returns true for Swift-specific patterns (let, var, guard let, etc.)
   - Returns false for plain text without code

3. `calculateRelevance(text, hasCode, qualitySignals, baseScore, codeBonus)`:
   - Returns baseScore when no signals match
   - Adds points for matching quality signals
   - Adds codeBonus when hasCode is true
   - Caps at 100

Follow existing test patterns from sundell.test.ts.
  </action>
  <verify>`npm test src/utils/swift-analysis.test.ts` passes</verify>
  <done>All swift-analysis functions have tests covering main cases</done>
</task>

<task type="auto">
  <name>Task 2: Add tests for errors.ts</name>
  <files>src/utils/errors.test.ts</files>
  <action>
Create tests for the three utility functions:

1. `isError(value)`:
   - Returns true for Error instances
   - Returns true for Error subclasses
   - Returns false for strings, numbers, objects, null, undefined

2. `toErrorMessage(error)`:
   - Returns error.message for Error instances
   - Returns String(value) for non-Error values
   - Handles null, undefined, objects

3. `logError(context, error, details?)`:
   - Calls console.error with formatted message
   - Includes context prefix in brackets
   - Includes details object when provided
   - Use `vi.spyOn(console, 'error')` to verify output

Follow existing test patterns.
  </action>
  <verify>`npm test src/utils/errors.test.ts` passes</verify>
  <done>All error utility functions have tests covering main cases</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npm test` passes (all tests including new ones)
- [ ] `npm run lint` passes
- [ ] `npm run build` succeeds
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- Test files follow existing conventions (co-located, vitest patterns)
- Tests cover happy path and key edge cases
</success_criteria>

<output>
After completion, create `.planning/phases/02-test-infrastructure/02-01-SUMMARY.md`
</output>
